{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CREDIT CARD FRAUD DETECTION PROJECT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fraud Detection System – Project Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Problem Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "Many existing fraud detection systems fail to detect subtle fraudulent activities, leading to financial losses. Your goal is to develop a fraud detection model that integrates with existing systems to identify the slightest credit fraud with high precision.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Develop an AI-driven fraud detection system that detects even small fraudulent activities in credit transactions.\n",
    "2. Ensure real-time fraud detection with minimal false positives to avoid disrupting genuine users.\n",
    "3. Create a system that seamlessly integrates with existing financial systems.\n",
    "4. Utilize advanced techniques like anomaly detection, behavioral biometrics, and contextual analysis.\n",
    "5. Implement a self-learning mechanism that adapts to new fraud patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Time :The number of seconds elapsed between the first transaction in the dataset and the current transaction.\n",
    "\n",
    "2. Amount: The transaction amount in currency units (e.g., USD or EUR).\n",
    "3. Class: The target variable: 0 for non-fraudulent transactions, 1 for fraudulent transactions.\n",
    "4. V1 to V28 – These are principal components obtained through PCA (Principal Component Analysis). They are anonymized      features derived from the original transaction details to protect sensitive information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 284807 entries, 0 to 284806\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   Time    284807 non-null  float64\n",
      " 1   V1      284807 non-null  float64\n",
      " 2   V2      284807 non-null  float64\n",
      " 3   V3      284807 non-null  float64\n",
      " 4   V4      284807 non-null  float64\n",
      " 5   V5      284807 non-null  float64\n",
      " 6   V6      284807 non-null  float64\n",
      " 7   V7      284807 non-null  float64\n",
      " 8   V8      284807 non-null  float64\n",
      " 9   V9      284807 non-null  float64\n",
      " 10  V10     284807 non-null  float64\n",
      " 11  V11     284807 non-null  float64\n",
      " 12  V12     284807 non-null  float64\n",
      " 13  V13     284807 non-null  float64\n",
      " 14  V14     284807 non-null  float64\n",
      " 15  V15     284807 non-null  float64\n",
      " 16  V16     284807 non-null  float64\n",
      " 17  V17     284807 non-null  float64\n",
      " 18  V18     284807 non-null  float64\n",
      " 19  V19     284807 non-null  float64\n",
      " 20  V20     284807 non-null  float64\n",
      " 21  V21     284807 non-null  float64\n",
      " 22  V22     284807 non-null  float64\n",
      " 23  V23     284807 non-null  float64\n",
      " 24  V24     284807 non-null  float64\n",
      " 25  V25     284807 non-null  float64\n",
      " 26  V26     284807 non-null  float64\n",
      " 27  V27     284807 non-null  float64\n",
      " 28  V28     284807 non-null  float64\n",
      " 29  Amount  284807 non-null  float64\n",
      " 30  Class   284807 non-null  int64  \n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 67.4 MB\n",
      "Dataset Info: None\n",
      "========\n",
      "Number of Rows in the Dataset:,31\n",
      "Number of Columns in the Dataset:,284807\n",
      "====\n",
      "Numerical Summary Statistics:\n",
      "                Time            V1            V2            V3            V4  \\\n",
      "count  284807.000000  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
      "mean    94813.859575  1.168375e-15  3.416908e-16 -1.379537e-15  2.074095e-15   \n",
      "std     47488.145955  1.958696e+00  1.651309e+00  1.516255e+00  1.415869e+00   \n",
      "min         0.000000 -5.640751e+01 -7.271573e+01 -4.832559e+01 -5.683171e+00   \n",
      "25%     54201.500000 -9.203734e-01 -5.985499e-01 -8.903648e-01 -8.486401e-01   \n",
      "50%     84692.000000  1.810880e-02  6.548556e-02  1.798463e-01 -1.984653e-02   \n",
      "75%    139320.500000  1.315642e+00  8.037239e-01  1.027196e+00  7.433413e-01   \n",
      "max    172792.000000  2.454930e+00  2.205773e+01  9.382558e+00  1.687534e+01   \n",
      "\n",
      "                 V5            V6            V7            V8            V9  \\\n",
      "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
      "mean   9.604066e-16  1.487313e-15 -5.556467e-16  1.213481e-16 -2.406331e-15   \n",
      "std    1.380247e+00  1.332271e+00  1.237094e+00  1.194353e+00  1.098632e+00   \n",
      "min   -1.137433e+02 -2.616051e+01 -4.355724e+01 -7.321672e+01 -1.343407e+01   \n",
      "25%   -6.915971e-01 -7.682956e-01 -5.540759e-01 -2.086297e-01 -6.430976e-01   \n",
      "50%   -5.433583e-02 -2.741871e-01  4.010308e-02  2.235804e-02 -5.142873e-02   \n",
      "75%    6.119264e-01  3.985649e-01  5.704361e-01  3.273459e-01  5.971390e-01   \n",
      "max    3.480167e+01  7.330163e+01  1.205895e+02  2.000721e+01  1.559499e+01   \n",
      "\n",
      "       ...           V21           V22           V23           V24  \\\n",
      "count  ...  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
      "mean   ...  1.654067e-16 -3.568593e-16  2.578648e-16  4.473266e-15   \n",
      "std    ...  7.345240e-01  7.257016e-01  6.244603e-01  6.056471e-01   \n",
      "min    ... -3.483038e+01 -1.093314e+01 -4.480774e+01 -2.836627e+00   \n",
      "25%    ... -2.283949e-01 -5.423504e-01 -1.618463e-01 -3.545861e-01   \n",
      "50%    ... -2.945017e-02  6.781943e-03 -1.119293e-02  4.097606e-02   \n",
      "75%    ...  1.863772e-01  5.285536e-01  1.476421e-01  4.395266e-01   \n",
      "max    ...  2.720284e+01  1.050309e+01  2.252841e+01  4.584549e+00   \n",
      "\n",
      "                V25           V26           V27           V28         Amount  \\\n",
      "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  284807.000000   \n",
      "mean   5.340915e-16  1.683437e-15 -3.660091e-16 -1.227390e-16      88.349619   \n",
      "std    5.212781e-01  4.822270e-01  4.036325e-01  3.300833e-01     250.120109   \n",
      "min   -1.029540e+01 -2.604551e+00 -2.256568e+01 -1.543008e+01       0.000000   \n",
      "25%   -3.171451e-01 -3.269839e-01 -7.083953e-02 -5.295979e-02       5.600000   \n",
      "50%    1.659350e-02 -5.213911e-02  1.342146e-03  1.124383e-02      22.000000   \n",
      "75%    3.507156e-01  2.409522e-01  9.104512e-02  7.827995e-02      77.165000   \n",
      "max    7.519589e+00  3.517346e+00  3.161220e+01  3.384781e+01   25691.160000   \n",
      "\n",
      "               Class  \n",
      "count  284807.000000  \n",
      "mean        0.001727  \n",
      "std         0.041527  \n",
      "min         0.000000  \n",
      "25%         0.000000  \n",
      "50%         0.000000  \n",
      "75%         0.000000  \n",
      "max         1.000000  \n",
      "\n",
      "[8 rows x 31 columns]\n",
      "========\n",
      "Number of Duplicates values Per Column\n",
      "1081\n",
      "========\n",
      "Number of missing values per column\n",
      "Time      0\n",
      "V1        0\n",
      "V2        0\n",
      "V3        0\n",
      "V4        0\n",
      "V5        0\n",
      "V6        0\n",
      "V7        0\n",
      "V8        0\n",
      "V9        0\n",
      "V10       0\n",
      "V11       0\n",
      "V12       0\n",
      "V13       0\n",
      "V14       0\n",
      "V15       0\n",
      "V16       0\n",
      "V17       0\n",
      "V18       0\n",
      "V19       0\n",
      "V20       0\n",
      "V21       0\n",
      "V22       0\n",
      "V23       0\n",
      "V24       0\n",
      "V25       0\n",
      "V26       0\n",
      "V27       0\n",
      "V28       0\n",
      "Amount    0\n",
      "Class     0\n",
      "dtype: int64\n",
      "========\n",
      "Total Number of missing Values in the dataset\n",
      "Time      0\n",
      "V1        0\n",
      "V2        0\n",
      "V3        0\n",
      "V4        0\n",
      "V5        0\n",
      "V6        0\n",
      "V7        0\n",
      "V8        0\n",
      "V9        0\n",
      "V10       0\n",
      "V11       0\n",
      "V12       0\n",
      "V13       0\n",
      "V14       0\n",
      "V15       0\n",
      "V16       0\n",
      "V17       0\n",
      "V18       0\n",
      "V19       0\n",
      "V20       0\n",
      "V21       0\n",
      "V22       0\n",
      "V23       0\n",
      "V24       0\n",
      "V25       0\n",
      "V26       0\n",
      "V27       0\n",
      "V28       0\n",
      "Amount    0\n",
      "Class     0\n",
      "dtype: int64\n",
      "========\n",
      "Print Nununique values per column\n",
      "Time      124592\n",
      "V1        275663\n",
      "V2        275663\n",
      "V3        275663\n",
      "V4        275663\n",
      "V5        275663\n",
      "V6        275663\n",
      "V7        275663\n",
      "V8        275663\n",
      "V9        275663\n",
      "V10       275663\n",
      "V11       275663\n",
      "V12       275663\n",
      "V13       275663\n",
      "V14       275663\n",
      "V15       275663\n",
      "V16       275663\n",
      "V17       275663\n",
      "V18       275663\n",
      "V19       275663\n",
      "V20       275663\n",
      "V21       275663\n",
      "V22       275663\n",
      "V23       275663\n",
      "V24       275663\n",
      "V25       275663\n",
      "V26       275663\n",
      "V27       275663\n",
      "V28       275663\n",
      "Amount     32767\n",
      "Class          2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Import the necessary V\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "class DataUnderstanding:\n",
    "    def __init__(self, df: pd.DataFrame):\n",
    "        self.df = df\n",
    "\n",
    "    def dataset_info(self):\n",
    "        print(\"Dataset Info:\", self.df.info())\n",
    "        print(\"=\"*8)\n",
    "\n",
    "         \n",
    "        print(f\"Number of Rows in the Dataset:,{self.df.shape[1]}\")\n",
    "        print(f\"Number of Columns in the Dataset:,{self.df.shape[0]}\")\n",
    "\n",
    "        # Summary Statistics of the dataset\n",
    "    def summary_statistics(self):\n",
    "        print(\"=\"*4)\n",
    "        print(\"Numerical Summary Statistics:\")\n",
    "        print(self.df.describe())\n",
    "\n",
    "        # print(\"Categorical Summary Statistics:\")\n",
    "        # print(self.df.describe(include =[\"object\"]))\n",
    "\n",
    "    def data_Quality_Checks(self):\n",
    "        print(\"=\"* 8)\n",
    "        print(\"Number of Duplicates values Per Column\")\n",
    "        print(self.df.duplicated().sum())\n",
    "\n",
    "        print(\"=\" * 8)\n",
    "        print(\"Number of missing values per column\")\n",
    "        print(self.df.isna().sum())\n",
    "\n",
    "        print(\"=\" * 8)\n",
    "        print(\"Total Number of missing Values in the dataset\")\n",
    "        print(self.df.isna().isna().sum())\n",
    "\n",
    "        print(\"=\" * 8)\n",
    "        print(\"Print Nununique values per column\")\n",
    "        print(self.df.nunique())\n",
    "\n",
    "\n",
    "    def run_all_checks(self):\n",
    "        \"\"\"Runs all overview checks.\"\"\"\n",
    "        self.dataset_info()\n",
    "        self.summary_statistics()\n",
    "        self.data_Quality_Checks()\n",
    "        \n",
    "\n",
    "\n",
    " \n",
    "df = pd.read_csv(\"creditcard.csv\")\n",
    "data = DataUnderstanding(df)\n",
    "data.run_all_checks()\n",
    "\n",
    "\n",
    "        \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overall Observation\n",
    "**Classes:**\n",
    "- 0 (Legit Transactions): 99.83% (284,315 instances)\n",
    "- 1 (Fraudulent Transactions): 0.17% (492 instances)\n",
    "- Highly Imbalanced Dataset: Fraudulent transactions are extremely rare.\n",
    "\n",
    "- PCA-transformed features: These components do not have real-world meanings but capture variance in the data.\n",
    "- Transaction Amount: A wide range from $0 to $25,691, with most values concentrated below $100."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- No missing values were found, ensuring completeness.\n",
    "This reduced the need for imputation or data loss through row deletions.\n",
    "\n",
    "- Duplicate Entries Present \n",
    "\n",
    "1081 duplicate rows were found and successfully removed.\n",
    "This step was crucial to prevent biased model training.\n",
    "\n",
    "- Outliers Were Mainly in Transaction Amount \n",
    "\n",
    "The \"Amount\" feature showed extreme values (some transactions exceeded $25,000).\n",
    "Log transformation was applied to handle skewness and improve model performance.\n",
    "Class Imbalance in Fraudulent Transactions ⚖️\n",
    "\n",
    "- The dataset was highly imbalanced (fraud cases = 0.17%).\n",
    "SMOTE (Synthetic Minority Oversampling Technique) was used to generate synthetic fraud cases and balance the dataset.\n",
    "Final Takeaway 🎯\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Fraud",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
